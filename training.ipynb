{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple demo neural network classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "def build_classifier(num_classes):\n",
    "\n",
    "    classifier = Sequential([\n",
    "        Dense(2048, activation='relu', input_shape=(1700, )),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    classifier.compile(optimizer='adam',\n",
    "                       loss='categorical_crossentropy',\n",
    "                       metrics=['accuracy',])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate 25 haplotype vectors w/ disease and 25 healthy vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_healthy = [np.zeros(1700) for _ in range(25)]\n",
    "y_healthy = [0. for _ in range(25)]\n",
    "X_diseased = [np.ones(1700) for _ in range(25)]\n",
    "y_diseased = [1. for _ in range(25)]\n",
    "\n",
    "X = np.array(X_healthy + X_diseased)\n",
    "y = np.array(y_healthy + y_diseased)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-Hot Encode Output Labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.utils import to_categorical\n",
    "\n",
    "y1hot = to_categorical(y, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Cross Validation\n",
    "Since we don't have many people represented in our data, we'll do leave-one-out cross validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 0.6236 - acc: 1.0000 - val_loss: 0.6940 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.3431 - acc: 0.5102 - val_loss: 0.6915 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3387 - acc: 1.0000 - val_loss: 0.6885 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3372 - acc: 1.0000 - val_loss: 0.6858 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3359 - acc: 1.0000 - val_loss: 0.6817 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3339 - acc: 1.0000 - val_loss: 0.6769 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3315 - acc: 1.0000 - val_loss: 0.6717 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3290 - acc: 1.0000 - val_loss: 0.6661 - val_acc: 1.0000\n",
      "Fold 2\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 1.0902 - acc: 0.4898 - val_loss: 0.6942 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.5565 - acc: 0.5102 - val_loss: 0.6944 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3560 - acc: 0.5102 - val_loss: 0.6937 - val_acc: 0.0000e+00\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3403 - acc: 0.5102 - val_loss: 0.6927 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3393 - acc: 1.0000 - val_loss: 0.6912 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3386 - acc: 1.0000 - val_loss: 0.6898 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3378 - acc: 1.0000 - val_loss: 0.6882 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3371 - acc: 1.0000 - val_loss: 0.6865 - val_acc: 1.0000\n",
      "Fold 3\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 0.5054 - acc: 1.0000 - val_loss: 0.6983 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.3420 - acc: 0.5102 - val_loss: 0.6936 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3397 - acc: 0.5102 - val_loss: 0.6909 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3384 - acc: 1.0000 - val_loss: 0.6898 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3379 - acc: 1.0000 - val_loss: 0.6888 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3374 - acc: 1.0000 - val_loss: 0.6879 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3369 - acc: 1.0000 - val_loss: 0.6869 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3364 - acc: 1.0000 - val_loss: 0.6859 - val_acc: 1.0000\n",
      "Fold 4\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 0.7981 - acc: 0.4898 - val_loss: 0.6977 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.3417 - acc: 0.5102 - val_loss: 0.6957 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3407 - acc: 0.5102 - val_loss: 0.6926 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3392 - acc: 1.0000 - val_loss: 0.6891 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3375 - acc: 1.0000 - val_loss: 0.6857 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3359 - acc: 1.0000 - val_loss: 0.6827 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3344 - acc: 1.0000 - val_loss: 0.6789 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3325 - acc: 1.0000 - val_loss: 0.6746 - val_acc: 1.0000\n",
      "Fold 5\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 1.2166 - acc: 0.4898 - val_loss: 0.6936 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 1.0719 - acc: 0.0000e+00 - val_loss: 0.6944 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 1.4182 - acc: 0.0000e+00 - val_loss: 0.6957 - val_acc: 0.0000e+00\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.6974 - acc: 0.0000e+00 - val_loss: 0.6963 - val_acc: 0.0000e+00\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.6930 - acc: 0.5102 - val_loss: 0.6964 - val_acc: 0.0000e+00\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.7942 - acc: 0.0000e+00 - val_loss: 0.6968 - val_acc: 0.0000e+00\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.6813 - acc: 0.5102 - val_loss: 0.6977 - val_acc: 0.0000e+00\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3530 - acc: 0.5102 - val_loss: 0.6974 - val_acc: 0.0000e+00\n",
      "Fold 6\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 0.9262 - acc: 0.4898 - val_loss: 0.6943 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.4633 - acc: 0.5102 - val_loss: 0.6942 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3593 - acc: 0.5102 - val_loss: 0.6911 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3407 - acc: 1.0000 - val_loss: 0.6868 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3367 - acc: 1.0000 - val_loss: 0.6823 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3343 - acc: 1.0000 - val_loss: 0.6779 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3320 - acc: 1.0000 - val_loss: 0.6733 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3298 - acc: 1.0000 - val_loss: 0.6685 - val_acc: 1.0000\n",
      "Fold 7\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 0.6314 - acc: 1.0000 - val_loss: 0.6952 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.3406 - acc: 0.5102 - val_loss: 0.6926 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3392 - acc: 1.0000 - val_loss: 0.6894 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3376 - acc: 1.0000 - val_loss: 0.6871 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3365 - acc: 1.0000 - val_loss: 0.6841 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3351 - acc: 1.0000 - val_loss: 0.6808 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3335 - acc: 1.0000 - val_loss: 0.6772 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3317 - acc: 1.0000 - val_loss: 0.6734 - val_acc: 1.0000\n",
      "Fold 8\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 0.8931 - acc: 0.4898 - val_loss: 0.6986 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.3422 - acc: 0.5102 - val_loss: 0.6971 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3414 - acc: 0.5102 - val_loss: 0.6939 - val_acc: 0.0000e+00\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3399 - acc: 0.5102 - val_loss: 0.6915 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3387 - acc: 1.0000 - val_loss: 0.6888 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3373 - acc: 1.0000 - val_loss: 0.6866 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3363 - acc: 1.0000 - val_loss: 0.6843 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3352 - acc: 1.0000 - val_loss: 0.6817 - val_acc: 1.0000\n",
      "Fold 9\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 0.5981 - acc: 1.0000 - val_loss: 0.6951 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.3405 - acc: 0.5102 - val_loss: 0.6934 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3396 - acc: 0.5102 - val_loss: 0.6904 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3382 - acc: 1.0000 - val_loss: 0.6874 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3367 - acc: 1.0000 - val_loss: 0.6854 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3357 - acc: 1.0000 - val_loss: 0.6833 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3347 - acc: 1.0000 - val_loss: 0.6809 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3335 - acc: 1.0000 - val_loss: 0.6782 - val_acc: 1.0000\n",
      "Fold 10\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 0.5537 - acc: 1.0000 - val_loss: 0.6964 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.3411 - acc: 0.5102 - val_loss: 0.6943 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3401 - acc: 0.5102 - val_loss: 0.6919 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3389 - acc: 1.0000 - val_loss: 0.6901 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3380 - acc: 1.0000 - val_loss: 0.6884 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3372 - acc: 1.0000 - val_loss: 0.6868 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3364 - acc: 1.0000 - val_loss: 0.6852 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3356 - acc: 1.0000 - val_loss: 0.6834 - val_acc: 1.0000\n",
      "Fold 11\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 1.3215 - acc: 0.4898 - val_loss: 0.6962 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.3416 - acc: 0.5102 - val_loss: 0.6960 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3409 - acc: 0.5102 - val_loss: 0.6945 - val_acc: 0.0000e+00\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3402 - acc: 0.5102 - val_loss: 0.6923 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3391 - acc: 1.0000 - val_loss: 0.6894 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3377 - acc: 1.0000 - val_loss: 0.6854 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3357 - acc: 1.0000 - val_loss: 0.6807 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3334 - acc: 1.0000 - val_loss: 0.6756 - val_acc: 1.0000\n",
      "Fold 12\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 0.5234 - acc: 1.0000 - val_loss: 0.6988 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.3423 - acc: 0.5102 - val_loss: 0.6954 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3406 - acc: 0.5102 - val_loss: 0.6921 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/8\n",
      " - 0s - loss: 0.3390 - acc: 1.0000 - val_loss: 0.6905 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3382 - acc: 1.0000 - val_loss: 0.6890 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3375 - acc: 1.0000 - val_loss: 0.6879 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3369 - acc: 1.0000 - val_loss: 0.6869 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3365 - acc: 1.0000 - val_loss: 0.6860 - val_acc: 1.0000\n",
      "Fold 13\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 1.3952 - acc: 0.4898 - val_loss: 0.6990 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.3424 - acc: 0.5102 - val_loss: 0.6983 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3420 - acc: 0.5102 - val_loss: 0.6963 - val_acc: 0.0000e+00\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3410 - acc: 0.5102 - val_loss: 0.6933 - val_acc: 0.0000e+00\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3396 - acc: 0.5102 - val_loss: 0.6922 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3391 - acc: 1.0000 - val_loss: 0.6912 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3385 - acc: 1.0000 - val_loss: 0.6901 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3380 - acc: 1.0000 - val_loss: 0.6890 - val_acc: 1.0000\n",
      "Fold 14\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 0.9172 - acc: 0.4898 - val_loss: 0.6951 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.3536 - acc: 0.5102 - val_loss: 0.6945 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3408 - acc: 0.5102 - val_loss: 0.6921 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3390 - acc: 1.0000 - val_loss: 0.6891 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3375 - acc: 1.0000 - val_loss: 0.6859 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3359 - acc: 1.0000 - val_loss: 0.6820 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3340 - acc: 1.0000 - val_loss: 0.6770 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3316 - acc: 1.0000 - val_loss: 0.6715 - val_acc: 1.0000\n",
      "Fold 15\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 0.8953 - acc: 0.4898 - val_loss: 0.6937 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 1.1507 - acc: 0.0000e+00 - val_loss: 0.6953 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3987 - acc: 0.5102 - val_loss: 0.6949 - val_acc: 0.0000e+00\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3424 - acc: 0.5102 - val_loss: 0.6932 - val_acc: 0.0000e+00\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3396 - acc: 0.5102 - val_loss: 0.6908 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3384 - acc: 1.0000 - val_loss: 0.6882 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3371 - acc: 1.0000 - val_loss: 0.6859 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3360 - acc: 1.0000 - val_loss: 0.6834 - val_acc: 1.0000\n",
      "Fold 16\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 0.5831 - acc: 1.0000 - val_loss: 0.6974 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.3416 - acc: 0.5102 - val_loss: 0.6942 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3400 - acc: 0.5102 - val_loss: 0.6913 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3386 - acc: 1.0000 - val_loss: 0.6899 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3379 - acc: 1.0000 - val_loss: 0.6889 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3374 - acc: 1.0000 - val_loss: 0.6879 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3369 - acc: 1.0000 - val_loss: 0.6869 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3364 - acc: 1.0000 - val_loss: 0.6858 - val_acc: 1.0000\n",
      "Fold 17\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 0.8690 - acc: 0.4898 - val_loss: 0.6949 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.3659 - acc: 0.5102 - val_loss: 0.6933 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3398 - acc: 0.5102 - val_loss: 0.6906 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3383 - acc: 1.0000 - val_loss: 0.6881 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3370 - acc: 1.0000 - val_loss: 0.6852 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3356 - acc: 1.0000 - val_loss: 0.6822 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3341 - acc: 1.0000 - val_loss: 0.6790 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3326 - acc: 1.0000 - val_loss: 0.6757 - val_acc: 1.0000\n",
      "Fold 18\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 1.8462 - acc: 0.4898 - val_loss: 0.6946 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.3917 - acc: 0.5102 - val_loss: 0.6944 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3413 - acc: 0.5102 - val_loss: 0.6937 - val_acc: 0.0000e+00\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3398 - acc: 0.5102 - val_loss: 0.6926 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3392 - acc: 1.0000 - val_loss: 0.6911 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3385 - acc: 1.0000 - val_loss: 0.6896 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3378 - acc: 1.0000 - val_loss: 0.6879 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3369 - acc: 1.0000 - val_loss: 0.6860 - val_acc: 1.0000\n",
      "Fold 19\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 0.3583 - acc: 1.0000 - val_loss: 0.7022 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.3440 - acc: 0.5102 - val_loss: 0.6936 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3397 - acc: 0.5102 - val_loss: 0.6887 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3373 - acc: 1.0000 - val_loss: 0.6855 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3357 - acc: 1.0000 - val_loss: 0.6825 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3343 - acc: 1.0000 - val_loss: 0.6793 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3327 - acc: 1.0000 - val_loss: 0.6757 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3309 - acc: 1.0000 - val_loss: 0.6715 - val_acc: 1.0000\n",
      "Fold 20\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 0.5915 - acc: 1.0000 - val_loss: 0.6984 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.3421 - acc: 0.5102 - val_loss: 0.6959 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3408 - acc: 0.5102 - val_loss: 0.6919 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3389 - acc: 1.0000 - val_loss: 0.6905 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3382 - acc: 1.0000 - val_loss: 0.6888 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3374 - acc: 1.0000 - val_loss: 0.6870 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3365 - acc: 1.0000 - val_loss: 0.6850 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3355 - acc: 1.0000 - val_loss: 0.6830 - val_acc: 1.0000\n",
      "Fold 21\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 0.7025 - acc: 0.4898 - val_loss: 0.6980 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.3419 - acc: 0.5102 - val_loss: 0.6927 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3393 - acc: 1.0000 - val_loss: 0.6857 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3359 - acc: 1.0000 - val_loss: 0.6779 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3321 - acc: 1.0000 - val_loss: 0.6697 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3280 - acc: 1.0000 - val_loss: 0.6608 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3237 - acc: 1.0000 - val_loss: 0.6511 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3189 - acc: 1.0000 - val_loss: 0.6402 - val_acc: 1.0000\n",
      "Fold 22\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 0.5711 - acc: 1.0000 - val_loss: 0.6960 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.3409 - acc: 0.5102 - val_loss: 0.6941 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3400 - acc: 0.5102 - val_loss: 0.6912 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3385 - acc: 1.0000 - val_loss: 0.6902 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3381 - acc: 1.0000 - val_loss: 0.6891 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3375 - acc: 1.0000 - val_loss: 0.6880 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3370 - acc: 1.0000 - val_loss: 0.6871 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3365 - acc: 1.0000 - val_loss: 0.6861 - val_acc: 1.0000\n",
      "Fold 23\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 0.6793 - acc: 1.0000 - val_loss: 0.6945 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.3808 - acc: 0.5102 - val_loss: 0.6932 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3395 - acc: 0.5102 - val_loss: 0.6913 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3386 - acc: 1.0000 - val_loss: 0.6895 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3377 - acc: 1.0000 - val_loss: 0.6877 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3368 - acc: 1.0000 - val_loss: 0.6857 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3359 - acc: 1.0000 - val_loss: 0.6837 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/8\n",
      " - 0s - loss: 0.3349 - acc: 1.0000 - val_loss: 0.6816 - val_acc: 1.0000\n",
      "Fold 24\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 1.1876 - acc: 0.4898 - val_loss: 0.6943 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.4415 - acc: 0.5102 - val_loss: 0.6936 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3397 - acc: 0.5102 - val_loss: 0.6909 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3384 - acc: 1.0000 - val_loss: 0.6875 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3367 - acc: 1.0000 - val_loss: 0.6841 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3351 - acc: 1.0000 - val_loss: 0.6808 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3334 - acc: 1.0000 - val_loss: 0.6772 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3317 - acc: 1.0000 - val_loss: 0.6734 - val_acc: 1.0000\n",
      "Fold 25\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 0.4120 - acc: 1.0000 - val_loss: 0.6992 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.3425 - acc: 0.5102 - val_loss: 0.6944 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3401 - acc: 0.5102 - val_loss: 0.6897 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3378 - acc: 1.0000 - val_loss: 0.6865 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3363 - acc: 1.0000 - val_loss: 0.6834 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3347 - acc: 1.0000 - val_loss: 0.6799 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3330 - acc: 1.0000 - val_loss: 0.6761 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3312 - acc: 1.0000 - val_loss: 0.6720 - val_acc: 1.0000\n",
      "Fold 26\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 1.8537 - acc: 0.5102 - val_loss: 0.0108 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.3600 - acc: 0.4898 - val_loss: 1.5582e-04 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3546 - acc: 0.4898 - val_loss: 2.6226e-06 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3538 - acc: 0.4898 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3534 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3531 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3527 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3523 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Fold 27\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 2s - loss: 0.5523 - acc: 1.0000 - val_loss: 4.9115e-05 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.3546 - acc: 0.4898 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3540 - acc: 0.4898 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3527 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3515 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3503 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3492 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3482 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Fold 28\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 2s - loss: 0.6154 - acc: 1.0000 - val_loss: 1.7881e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.3558 - acc: 0.4898 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3539 - acc: 0.4898 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3517 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3500 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3482 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3463 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3441 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Fold 29\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 2s - loss: 0.6879 - acc: 1.0000 - val_loss: 7.2840e-05 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.3549 - acc: 0.4898 - val_loss: 3.5763e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3536 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3520 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3509 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3497 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3485 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3472 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Fold 30\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 2s - loss: 0.7419 - acc: 0.5102 - val_loss: 3.5227e-04 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.3553 - acc: 0.4898 - val_loss: 9.5367e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3536 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3518 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3503 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3487 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3469 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3449 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Fold 31\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 2s - loss: 0.7865 - acc: 0.5102 - val_loss: 4.2319e-06 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.3559 - acc: 0.4898 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3542 - acc: 0.4898 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3513 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3485 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3460 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3432 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3394 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Fold 32\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 2s - loss: 0.5917 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.3575 - acc: 0.4898 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3548 - acc: 0.4898 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3516 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3484 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3453 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3423 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3390 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Fold 33\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 2s - loss: 0.8555 - acc: 0.5102 - val_loss: 0.0079 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.3587 - acc: 0.4898 - val_loss: 6.1989e-06 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3541 - acc: 0.4898 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3534 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3527 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3518 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3509 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3499 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Fold 34\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 2s - loss: 1.4112 - acc: 0.5102 - val_loss: 0.0079 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.3588 - acc: 0.4898 - val_loss: 3.2306e-05 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3544 - acc: 0.4898 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3535 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3525 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3515 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3506 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3496 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Fold 35\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 2s - loss: 0.4752 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.3566 - acc: 0.4898 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3548 - acc: 0.4898 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3533 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3523 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3516 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3509 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3504 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Fold 36\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 2s - loss: 0.7283 - acc: 0.5102 - val_loss: 0.0112 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.3603 - acc: 0.4898 - val_loss: 1.3871e-04 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3545 - acc: 0.4898 - val_loss: 1.4901e-06 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3536 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3528 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3522 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3516 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3510 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Fold 37\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 2s - loss: 0.5133 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.3563 - acc: 0.4898 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3543 - acc: 0.4898 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3525 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3518 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3512 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3505 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3497 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Fold 38\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 2s - loss: 0.7034 - acc: 0.5102 - val_loss: 2.5630e-05 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.3549 - acc: 0.4898 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3537 - acc: 0.4898 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3524 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3512 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3499 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3481 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3459 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Fold 39\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 2s - loss: 0.9439 - acc: 0.5102 - val_loss: 4.4108e-06 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.3557 - acc: 0.4898 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3552 - acc: 0.4898 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3538 - acc: 0.4898 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3527 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3521 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3514 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3507 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Fold 40\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 2s - loss: 0.6602 - acc: 1.0000 - val_loss: 0.0470 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.3768 - acc: 0.4898 - val_loss: 1.8473e-04 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3527 - acc: 1.0000 - val_loss: 1.1921e-06 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3511 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3497 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3484 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3473 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3458 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Fold 41\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 2s - loss: 1.7552 - acc: 0.5102 - val_loss: 0.0388 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.3737 - acc: 0.4898 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3553 - acc: 0.4898 - val_loss: 2.0488e-04 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3524 - acc: 1.0000 - val_loss: 1.3948e-05 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3504 - acc: 1.0000 - val_loss: 9.5367e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3483 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3461 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3437 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Fold 42\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 2s - loss: 0.8960 - acc: 0.5102 - val_loss: 2.6226e-06 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.3560 - acc: 0.4898 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3548 - acc: 0.4898 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3537 - acc: 0.4898 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3524 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3515 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3506 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3495 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Fold 43\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 2s - loss: 0.4522 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.3566 - acc: 0.4898 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3528 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3498 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3471 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3443 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3411 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3375 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Fold 44\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 2s - loss: 0.7337 - acc: 0.5102 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.3567 - acc: 0.4898 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3559 - acc: 0.4898 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3542 - acc: 0.4898 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3533 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3526 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3520 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3515 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Fold 45\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 2s - loss: 0.9017 - acc: 0.5102 - val_loss: 0.0325 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.3706 - acc: 0.4898 - val_loss: 5.0259e-04 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3548 - acc: 0.4898 - val_loss: 5.9605e-06 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3538 - acc: 0.4898 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3531 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3522 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3515 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3497 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Fold 46\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 2s - loss: 0.5027 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.3560 - acc: 0.4898 - val_loss: 1.1921e-07 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/8\n",
      " - 0s - loss: 0.3539 - acc: 0.4898 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3525 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3519 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3513 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3508 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3502 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Fold 47\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 3s - loss: 0.5220 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.3560 - acc: 0.4898 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3533 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3501 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3472 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3441 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3410 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3375 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Fold 48\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 3s - loss: 0.4463 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.3567 - acc: 0.4898 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3536 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3519 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3511 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3502 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3492 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3482 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Fold 49\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 3s - loss: 0.7127 - acc: 0.5102 - val_loss: 1.4503e-04 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.3547 - acc: 0.4898 - val_loss: 3.5763e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3539 - acc: 0.4898 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3524 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3505 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3488 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3468 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3447 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Fold 50\n",
      "Train on 49 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 3s - loss: 0.6362 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.3572 - acc: 0.4898 - val_loss: 5.0665e-05 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.3530 - acc: 1.0000 - val_loss: 4.7684e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.3511 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.3491 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.3470 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.3448 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 0.3425 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=50)\n",
    "fold_number = 1\n",
    "for train_index, val_index in kf.split(X):\n",
    "    print(\"Fold \" + str(fold_number))\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y1hot[train_index], y1hot[val_index]\n",
    "    classifier = build_classifier(num_classes=num_classes)\n",
    "    classifier.fit(X_train, y_train, batch_size=49, epochs=8, validation_data=(X_val, y_val), verbose=2)\n",
    "    classifier.save_weights(\"fold{}.weights.hdf5\".format(fold_number))\n",
    "    fold_number += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict phenotype on test data using ensemble average of K models\n",
    "Generate dummy test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = [(np.zeros(1700), 0) if np.random.choice(2) == 0 else (np.ones(1700), 1) for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = zip(*test_set) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test1hot = to_categorical(y_test, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for fold in range(50):\n",
    "    model = build_classifier(num_classes=num_classes)\n",
    "    model.load_weights(\"fold{}.weights.hdf5\".format(fold + 1))\n",
    "    predictions.append(model.predict(np.array(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_predictions = np.mean(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(avg_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[6 0]\n",
      " [0 4]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUgAAAEmCAYAAAAA6gkZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdb14427e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=[\"healthy\", \"diseased\"],\n",
    "                      title='Confusion matrix, without normalization')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
