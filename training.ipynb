{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple demo neural network classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "def build_classifier(num_classes, num_dimensions=1781):\n",
    "\n",
    "    classifier = Sequential([\n",
    "        Dense(1024, activation='relu', input_shape=(num_dimensions, )),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    classifier.compile(optimizer='adam',\n",
    "                       loss='categorical_crossentropy',\n",
    "                       metrics=['accuracy',])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "with open(\"counts/SRR_47normal_small.list\") as normal_subjects_file:\n",
    "    healthy_subjects = [line.strip() for line in normal_subjects_file]\n",
    "\n",
    "with open(\"counts/SRR_50aml_small.list\") as diseased_subjects_file:\n",
    "    diseased_subjects = [line.strip() for line in diseased_subjects_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 50\n"
     ]
    }
   ],
   "source": [
    "print(len(healthy_subjects), len(diseased_subjects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(subjects_array):\n",
    "    a = []\n",
    "    for person in subjects_array:\n",
    "        try:\n",
    "            with open(\"counts/\" + person + \".count\") as person_file:\n",
    "                vector = [line.strip().split()[-1] for line in person_file]\n",
    "                a.append(np.array(vector))\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "    return a\n",
    "\n",
    "X_healthy = load_data(healthy_subjects)\n",
    "y_healthy = [0. for _ in range(len(X_healthy))]\n",
    "X_diseased = load_data(diseased_subjects)\n",
    "y_diseased = [1. for _ in range(len(X_diseased))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 42\n",
      "27 42\n"
     ]
    }
   ],
   "source": [
    "print(len(X_healthy), len(X_diseased))\n",
    "print(len(y_healthy), len(y_diseased))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X_healthy + X_diseased)\n",
    "y = np.array(y_healthy + y_diseased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_people = len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-Hot Encode Output Labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.utils import to_categorical\n",
    "\n",
    "y1hot = to_categorical(y, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Cross Validation\n",
    "Since we don't have many people represented in our data, we'll do leave-one-out cross validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 9.1523 - acc: 0.3676 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 4/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 5/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 6/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 7/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 8/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "['loss', 'acc']\n",
      "[16.11809539794922, 0.0]\n",
      "Fold 2\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 5.2877 - acc: 0.5882 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "['loss', 'acc']\n",
      "[1.1920930376163597e-07, 1.0]\n",
      "Fold 3\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 3.0945 - acc: 0.7500 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "['loss', 'acc']\n",
      "[1.1920930376163597e-07, 1.0]\n",
      "Fold 4\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "['loss', 'acc']\n",
      "[1.1920930376163597e-07, 1.0]\n",
      "Fold 5\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 4/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 5/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 6/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 7/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 8/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "['loss', 'acc']\n",
      "[16.11809539794922, 0.0]\n",
      "Fold 6\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 5.5086 - acc: 0.6176 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "['loss', 'acc']\n",
      "[1.1920930376163597e-07, 1.0]\n",
      "Fold 7\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 3.0280 - acc: 0.7206 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "['loss', 'acc']\n",
      "[1.1920930376163597e-07, 1.0]\n",
      "Fold 8\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "['loss', 'acc']\n",
      "[1.1920930376163597e-07, 1.0]\n",
      "Fold 9\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 9.9554 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "['loss', 'acc']\n",
      "[1.1920930376163597e-07, 1.0]\n",
      "Fold 10\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "['loss', 'acc']\n",
      "[1.1920930376163597e-07, 1.0]\n",
      "Fold 11\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 4/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 6/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 7/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 8/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "['loss', 'acc']\n",
      "[16.11809539794922, 0.0]\n",
      "Fold 12\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 5.9427 - acc: 0.5147 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 0.7111 - acc: 0.9559 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 0.7111 - acc: 0.9559 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.7111 - acc: 0.9559 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 0.7111 - acc: 0.9559 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 0.7111 - acc: 0.9559 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 0.6459 - acc: 0.9559 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 8.7701 - acc: 0.4559 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "['loss', 'acc']\n",
      "[1.1920930376163597e-07, 1.0]\n",
      "Fold 13\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "['loss', 'acc']\n",
      "[1.1920930376163597e-07, 1.0]\n",
      "Fold 14\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 4.4645 - acc: 0.6471 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "['loss', 'acc']\n",
      "[1.1920930376163597e-07, 1.0]\n",
      "Fold 15\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 9.4882 - acc: 0.3824 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 4/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 5/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 6/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 7/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 8/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "['loss', 'acc']\n",
      "[16.11809539794922, 0.0]\n",
      "Fold 16\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 5.7856 - acc: 0.6176 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "['loss', 'acc']\n",
      "[1.1920930376163597e-07, 1.0]\n",
      "Fold 17\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 6.0617 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 4/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 5/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 6/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 7/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 8/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "['loss', 'acc']\n",
      "[16.11809539794922, 0.0]\n",
      "Fold 18\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 5.3996 - acc: 0.5882 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 4/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 5/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 6/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 7/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 8/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "['loss', 'acc']\n",
      "[16.11809539794922, 0.0]\n",
      "Fold 19\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "['loss', 'acc']\n",
      "[1.1920930376163597e-07, 1.0]\n",
      "Fold 20\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 6.1606 - acc: 0.6176 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "['loss', 'acc']\n",
      "[1.1920930376163597e-07, 1.0]\n",
      "Fold 21\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 5.6426 - acc: 0.6176 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "[1.1920930376163597e-07, 1.0]\n",
      "Fold 22\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 9.9602 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "['loss', 'acc']\n",
      "[1.1920930376163597e-07, 1.0]\n",
      "Fold 23\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 5.4625 - acc: 0.6176 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "['loss', 'acc']\n",
      "[1.1920930376163597e-07, 1.0]\n",
      "Fold 24\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 4.4679 - acc: 0.5441 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 4/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 5/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 6/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 7/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 8/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "['loss', 'acc']\n",
      "[16.11809539794922, 0.0]\n",
      "Fold 25\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "['loss', 'acc']\n",
      "[1.1920930376163597e-07, 1.0]\n",
      "Fold 26\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 1s - loss: 9.3623 - acc: 0.2647 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 4/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 5/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 6/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 7/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 8/8\n",
      " - 0s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "['loss', 'acc']\n",
      "[16.11809539794922, 0.0]\n",
      "Fold 27\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 2s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 9.9553 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "['loss', 'acc']\n",
      "[1.1920930376163597e-07, 1.0]\n",
      "Fold 28\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 2s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 4/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 5/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 6/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 7/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 8/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "['loss', 'acc']\n",
      "[16.11809539794922, 0.0]\n",
      "Fold 29\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 2s - loss: 3.9972 - acc: 0.6029 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 4/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 5/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 6/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 7/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 8/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "['loss', 'acc']\n",
      "[16.11809539794922, 0.0]\n",
      "Fold 30\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 2s - loss: 4.2810 - acc: 0.6176 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "['loss', 'acc']\n",
      "[1.1920930376163597e-07, 1.0]\n",
      "Fold 31\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 2s - loss: 3.8463 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 4/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 5/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 6/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 7/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 8/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "['loss', 'acc']\n",
      "[16.11809539794922, 0.0]\n",
      "Fold 32\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 2s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 5/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 6/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 7/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 8/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "['loss', 'acc']\n",
      "[16.11809539794922, 0.0]\n",
      "Fold 33\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 2s - loss: 9.7142 - acc: 0.3971 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "['loss', 'acc']\n",
      "[1.1920930376163597e-07, 1.0]\n",
      "Fold 34\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 2s - loss: 8.3257 - acc: 0.3971 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "['loss', 'acc']\n",
      "[1.1920930376163597e-07, 1.0]\n",
      "Fold 35\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 2s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "['loss', 'acc']\n",
      "[1.1920930376163597e-07, 1.0]\n",
      "Fold 36\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 2s - loss: 4.1464 - acc: 0.6324 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 4/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 5/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 6/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 7/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 8/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "['loss', 'acc']\n",
      "[16.11809539794922, 0.0]\n",
      "Fold 37\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 2s - loss: 5.0194 - acc: 0.6029 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 4/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 5/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 6/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 7/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 8/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "['loss', 'acc']\n",
      "[16.11809539794922, 0.0]\n",
      "Fold 38\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 2s - loss: 11.6719 - acc: 0.2059 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 4/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 5/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 6/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 7/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 8/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "['loss', 'acc']\n",
      "[16.11809539794922, 0.0]\n",
      "Fold 39\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 2s - loss: 7.3805 - acc: 0.3382 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 6.3546 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 6.2932 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 2.6813 - acc: 0.7647 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 5/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 6/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 7/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 8/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "['loss', 'acc']\n",
      "[16.11809539794922, 0.0]\n",
      "Fold 40\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 2s - loss: 6.8869 - acc: 0.4118 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "['loss', 'acc']\n",
      "[1.1920930376163597e-07, 1.0]\n",
      "Fold 41\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 2s - loss: 6.1628 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 4/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 5/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 6/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 7/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 8/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "['loss', 'acc']\n",
      "[16.11809539794922, 0.0]\n",
      "Fold 42\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 2s - loss: 6.2243 - acc: 0.6029 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 4/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 5/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 6/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 7/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "['loss', 'acc']\n",
      "[16.11809539794922, 0.0]\n",
      "Fold 43\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 2s - loss: 5.0954 - acc: 0.5588 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 4/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 5/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 6/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 7/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 8/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "['loss', 'acc']\n",
      "[16.11809539794922, 0.0]\n",
      "Fold 44\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 2s - loss: 9.7073 - acc: 0.3824 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 6.4416 - acc: 0.5147 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "['loss', 'acc']\n",
      "[1.1920930376163597e-07, 1.0]\n",
      "Fold 45\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 2s - loss: 5.0920 - acc: 0.6029 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 4/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 5/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 6/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 7/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 8/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "['loss', 'acc']\n",
      "[16.11809539794922, 0.0]\n",
      "Fold 46\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 3s - loss: 9.7209 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 4/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 5/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 6/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 7/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 8/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "['loss', 'acc']\n",
      "[16.11809539794922, 0.0]\n",
      "Fold 47\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 2s - loss: 6.4421 - acc: 0.4853 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "['loss', 'acc']\n",
      "[1.1920930376163597e-07, 1.0]\n",
      "Fold 48\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 3s - loss: 2.5090 - acc: 0.7500 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 4/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 5/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 6/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 7/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 8/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "['loss', 'acc']\n",
      "[16.11809539794922, 0.0]\n",
      "Fold 49\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 3s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "['loss', 'acc']\n",
      "[1.1920930376163597e-07, 1.0]\n",
      "Fold 50\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 3s - loss: 3.4704 - acc: 0.6912 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 3.0513 - acc: 0.7059 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 4/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 5/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 6/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 7/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 8/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "['loss', 'acc']\n",
      "[16.11809539794922, 0.0]\n",
      "Fold 51\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 3s - loss: 5.1721 - acc: 0.6176 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 4/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 5/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 6/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 7/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 8/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "['loss', 'acc']\n",
      "[16.11809539794922, 0.0]\n",
      "Fold 52\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 3s - loss: 2.8402 - acc: 0.6912 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 4/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 5/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 6/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 7/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 8/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "['loss', 'acc']\n",
      "[16.11809539794922, 0.0]\n",
      "Fold 53\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 3s - loss: 4.2243 - acc: 0.6324 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "['loss', 'acc']\n",
      "[1.1920930376163597e-07, 1.0]\n",
      "Fold 54\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 3s - loss: 6.3713 - acc: 0.3971 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "['loss', 'acc']\n",
      "[1.1920930376163597e-07, 1.0]\n",
      "Fold 55\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 3s - loss: 3.8583 - acc: 0.6912 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "['loss', 'acc']\n",
      "[1.1920930376163597e-07, 1.0]\n",
      "Fold 56\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 3s - loss: 5.1305 - acc: 0.4853 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "['loss', 'acc']\n",
      "[1.1920930376163597e-07, 1.0]\n",
      "Fold 57\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 3s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "['loss', 'acc']\n",
      "[1.1920930376163597e-07, 1.0]\n",
      "Fold 58\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 3s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "['loss', 'acc']\n",
      "[1.1920930376163597e-07, 1.0]\n",
      "Fold 59\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 3s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 4/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 5/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 6/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 7/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 8/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "['loss', 'acc']\n",
      "[16.11809539794922, 0.0]\n",
      "Fold 60\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 3s - loss: 2.9004 - acc: 0.6765 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 8.8651 - acc: 0.4412 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 5.6131 - acc: 0.6176 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 0.1834 - acc: 0.9853 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 5/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 6/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 7/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 8/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "['loss', 'acc']\n",
      "[16.11809539794922, 0.0]\n",
      "Fold 61\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 3s - loss: 6.3146 - acc: 0.6029 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 4/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 5/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 6/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 7/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 8/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "['loss', 'acc']\n",
      "[16.11809539794922, 0.0]\n",
      "Fold 62\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 3s - loss: 9.7422 - acc: 0.3824 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 4/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 5/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 6/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 7/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 8/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "['loss', 'acc']\n",
      "[16.11809539794922, 0.0]\n",
      "Fold 63\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 4s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 4/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 5/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 6/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 8/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "['loss', 'acc']\n",
      "[16.11809539794922, 0.0]\n",
      "Fold 64\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 4s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 3/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 4/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 5/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 6/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 7/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 8/8\n",
      " - 0s - loss: 9.7183 - acc: 0.3971 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "['loss', 'acc']\n",
      "[16.11809539794922, 0.0]\n",
      "Fold 65\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 4s - loss: 8.9583 - acc: 0.3971 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "['loss', 'acc']\n",
      "[1.1920930376163597e-07, 1.0]\n",
      "Fold 66\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 4s - loss: 4.4153 - acc: 0.5441 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "['loss', 'acc']\n",
      "[1.1920930376163597e-07, 1.0]\n",
      "Fold 67\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 4s - loss: 2.9466 - acc: 0.6618 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 2/8\n",
      " - 0s - loss: 8.0989 - acc: 0.4559 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 6.2948 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "['loss', 'acc']\n",
      "[1.1920930376163597e-07, 1.0]\n",
      "Fold 68\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 4s - loss: 9.0723 - acc: 0.3971 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "['loss', 'acc']\n",
      "[1.1920930376163597e-07, 1.0]\n",
      "Fold 69\n",
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/8\n",
      " - 4s - loss: 5.7506 - acc: 0.5000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      " - 0s - loss: 6.3998 - acc: 0.6029 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "['loss', 'acc']\n",
      "[1.1920930376163597e-07, 1.0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=num_people)\n",
    "fold_number = 1\n",
    "cvscores = []\n",
    "for train_index, val_index in kf.split(X):\n",
    "    print(\"Fold \" + str(fold_number))\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y1hot[train_index], y1hot[val_index]\n",
    "    classifier = build_classifier(num_classes=num_classes)\n",
    "    classifier.fit(X_train, y_train, batch_size=num_people, epochs=8, validation_data=(X_val, y_val), verbose=2)\n",
    "    scores = classifier.evaluate(X_val, y_val, verbose=0)\n",
    "    print(classifier.metrics_names)\n",
    "    print(scores)\n",
    "    cvscores.append(scores)\n",
    "    classifier.save_weights(\"fold{}.weights.hdf5\".format(fold_number))\n",
    "    del classifier\n",
    "    fold_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = np.array(cvscores)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55 (+/- 0.50)\n"
     ]
    }
   ],
   "source": [
    "print(\"%.2f (+/- %.2f)\" % (np.mean(accuracies), np.std(accuracies)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict phenotype on test data using ensemble average of K models\n",
    "Generate dummy test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = [(np.zeros(1700), 0) if np.random.choice(2) == 0 else (np.ones(1700), 1) for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = zip(*test_set) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test1hot = to_categorical(y_test, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for fold in range(50):\n",
    "    model = build_classifier(num_classes=num_classes)\n",
    "    model.load_weights(\"fold{}.weights.hdf5\".format(fold + 1))\n",
    "    predictions.append(model.predict(np.array(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_predictions = np.mean(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(avg_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[3 0]\n",
      " [0 7]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUgAAAEmCAYAAAAA6gkZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3XmcHFXZ9vHflZWwgwGUhDVAIEH2\nTRBBQAwQEVRkR3bhEQEBfVFQEUVRfBAEfBBQEJRVQFkUCMqqrAkB2WRHkrAkIPuSZHK/f5wzoTPp\nbZKeru6Z65tPfdJdfbrq7qmZu885deqUIgIzM5tbv6IDMDNrVU6QZmYVOEGamVXgBGlmVoETpJlZ\nBU6QZmYVOEHOI0lDJF0r6Q1JV8zHdvaUdFMjYyuKpM0l/btV9idpRUkhaUCzYmoXkp6TtE1+/B1J\n5/XAPs6W9N1Gb7eZ1NvHQUraAzgKWB14C5gInBQRd87ndvcGvg5sGhEz5zvQFicpgFUj4qmiY6lE\n0nPAgRFxc36+IvAsMLDRx0jSBcCkiDi+kdttlq4/qwZsb9+8vU82YnutolfXICUdBZwG/BhYBlge\n+BXw+QZsfgXgib6QHOvhWlrP8c+2QBHRKxdgMeBtYJcqZQaTEuiUvJwGDM6vbQlMAo4GXgFeBPbL\nr/0AmA7MyPs4ADgB+H3JtlcEAhiQn+8LPEOqxT4L7Fmy/s6S920K3Ae8kf/ftOS1W4EfAv/I27kJ\nGFrhs3XG/62S+HcCtgeeAF4DvlNSfiPgLuD1XPZMYFB+7fb8Wd7Jn3fXku3/P+Al4KLOdfk9I/I+\n1svPlwWmAVvWcex+BxydHw/L+/6f/HyVvF112d9FwCzgvRzjt0qOwVeA/+T9H1fn8Z/juOR1kfd/\ncD720/O+rq3wOQI4BHgS+C9wFh+22voBxwPP5+NzIbBYl9+dA3Lct5es2w94IW/vEGBD4KF83M4s\n2fcI4O/Aq/lz/wFYvOT154Bt8uMTyL+7+bi/XbLMBE7Irx0LPE363XsU2DmvXwN4H+jI73k9r78A\n+FHJPg8CnsrH7xpg2Xp+VoXmkaID6LEPBmPywR1QpcyJwN3A0sBSwD+BH+bXtszvPxEYSEos7wJL\ndP2lqvC88xd6ALAQ8CYwMr/2MWB01z9EYMn8y7F3ft/u+flH8uu35l/Q1YAh+fnJFT5bZ/zfy/Ef\nBEwFLgYWAUbnX+qVc/n1gU3yflcEHgOO7PILvEqZ7f+UlGiGUJKwSv4gHgMWBG4Efl7nsdufnHSA\nPfJnvqzktT+XxFC6v+fIf/RdjsG5Ob61gQ+ANeo4/rOPS7mfAV3++Ct8jgCuAxYntV6mAmNKPsdT\nwMrAwsBVwEVd4r6Q9LszpGTd2cACwLb5+P0pxz+MlGi3yNtYBfhMPjZLkZLsaeV+VnT53S0ps06O\ned38fBfSF10/0pfkO8DHqvy8Zv+MgK1IiXq9HNMZwO31/KyKXHpzE/sjwLSo3gTeEzgxIl6JiKmk\nmuHeJa/PyK/PiIi/kL4dR85jPLOANSUNiYgXI+KRMmV2AJ6MiIsiYmZEXAI8DnyupMz5EfFERLwH\nXE76Ja5kBqm/dQZwKTAUOD0i3sr7fwRYCyAixkfE3Xm/zwG/Brao4zN9PyI+yPHMISLOJdUI7iF9\nKRxXY3udbgM2l9QP+BTwM2Cz/NoW+fXu+EFEvBcRDwIPkhIl1D7+jXByRLweEf8BbuHD47UncGpE\nPBMRbwPfBnbr0pw+ISLe6fKz/WFEvB8RN5ES1CU5/snAHcC6ABHxVESMy8dmKnAqtY/nbJKWIiXf\nr0fEA3mbV0TElIiYFRGXkY7tRnVuck/gtxExISI+yJ/3E7mfuFOln1VhenOCfBUYWqP/ZllSE6fT\n83nd7G10SbDvkr7tuyUi3iF94x4CvCjpekmr1xFPZ0zDSp6/1I14Xo2Ijvy484/s5ZLX3+t8v6TV\nJF0n6SVJb5L6bYdW2TbA1Ih4v0aZc4E1gTPyH0ZNEfE06ctoHWBzUs1iiqSRzFuCrPQzq3X8G6E7\n+x5A6ivv9EKZ7XU9fpWO59KSLpU0OR/P31P7eJLfOxD4I3BxRFxasn4fSRMlvS7pddJxrWubdPm8\n+UvhVeb9d7spenOCvIvUBNmpSpkppJMtnZbP6+bFO6SmZKePlr4YETdGxGdINanHSYmjVjydMU2e\nx5i64/9Ica0aEYsC3yH181VTdQiEpIVJ/Xq/AU6QtGQ34rkN+BKpH3Ryfr4PsARpJEK34ymj2vGf\n43hKmuN4zsO+6tn3TOZMePOzj5/k96+Vj+de1D6enc4g9TPOPkMvaQXS7+xhpC6fxYGHS7ZZK9Y5\nPq+khUitvGb8bs+zXpsgI+INUv/bWZJ2krSgpIGStpP0s1zsEuB4SUtJGprL/34edzkR+JSk5SUt\nRmpCACBpGUk75l+KD0i1o44y2/gLsJqkPSQNkLQrMIpUg+ppi5D6Sd/OtdtDu7z+Mqm/rDtOB8ZH\nxIHA9aT+MwAknSDp1irvvY30x3h7fn4raVjVnSW14q66G2O14/8gMFrSOpIWIPXTzc++yu37G5JW\nyl8kPyb1szZqVMQi5BMmkoYB36znTZK+Sqql7xERs0peWoiUBKfmcvuRapCdXgaGSxpUYdMXA/vl\nn+dg0ue9J3fntKxemyABIuJU0hjI40kH9gXSH92fcpEfAfeTzgL+C5iQ183LvsYBl+VtjWfOpNaP\ndDZ8CukM3hbA/5TZxqvA2Fz2VdKZ2LERMW1eYuqmY0gnRN4i1RQu6/L6CcDvcvPqy7U2JunzpBNl\nh+RVRwHrSdozP1+OdDa+kttIf+SdCfJOUo3u9orvSLWm43OMx9SKkSrHPyKeIJ3EuZnU19Z13Oxv\ngFF5X3+i+35LOvN+O2lUw/ukL4BG+QHphMgbpC+nq+p83+6kxD9F0tt5+U5EPAr8L6ll9jLwceY8\nfn8n9Wm/JGmu39eI+BvwXeBK0iiJEcBu8/LBmqnXDxS31iRpIrB1/lIwa0lOkGZmFfTqJraZWSlJ\nI/OZ+M7lTUlHVizvGqSZ9UWS+pPOom8cEV2H1wGuQZpZ37U18HSl5AhpYKrVsNBiS8YSHx1Wu6A1\n1TILDy46BKtgwoTx0yJiqUZtr/+iK0TMnOtirbnEe1MfIY0I6HRORJxTofhupOFWFTlB1mGJjw7j\n62fPy0gO60lHbD6i6BCsgiEDVbFWNi9i5nsMHllzdBnvTzzr/YjYoFa5PF5zR0rGK5fjBGlmrU+C\nfv0bucXtgAkR8XK1Qk6QZtYe1NBTJrtTo3kNPkljZu1Cqr3UtRktSJoKrubVRa5BmlkbUMNqkBHx\nLmmijJqcIM2s9YlG90HWxQnSzNpA/U3oRnKCNLP20NiTNHVxgjSz9uAapJlZOY07SdMdTpBm1vp8\nksbMrBLXIM3MKuvnPkgzs7kJ1yDNzMpr+GQVdXGCNLP24GE+ZmYVuIltZlZGN2braSQnSDNrD+6D\nNDMrx+MgzcwqcxPbzKwMj4M0M6vE4yDNzCpzDdLMrIIC+iB9V0Mza33KZ7FrLXVtSotL+qOkxyU9\nJukTlcq6BmlmbUH9GlafOx24ISK+JGkQsGClgk6QZtbyBKgBTWxJiwKfAvYFiIjpwPRK5d3ENrPW\npzqX2lYGpgLnS3pA0nmSFqpU2AnSzNqAkGovwFBJ95csB3fZ0ABgPeD/ImJd4B3g2Ep7dRPbzNpC\nv/r6IKdFxAZVXp8ETIqIe/LzP1IlQboGaWZtoc4aZFUR8RLwgqSRedXWwKOVyrsGaWatr/4+xnp8\nHfhDPoP9DLBfpYJOkGbW8kR9NcR6RMREoFozfDYnSDNrC3X2QTaUE6SZtYVG1SC7wwnSzFpfY/sg\n6+YEaWZtwTVIM7MyhNwHaWZWkZvYZmZlyE1sM7OKnCDNzMooqg/S12L3ETOmf8CZh36B0w4cy6n7\njWHcBacVHZJlN914A2uNHsno1VfhlJ+dXHQ4rasx0511i2uQfcSAgYM46NSLGDxkITpmzuDsw3dj\n5EZbsPyodYsOrU/r6OjgyMO/xvV/Hcew4cP55CYbMnbsjqwxalTRobWWgvogXYPsIyQxeEiaF7Rj\n5kw6Zs4o5CZINqf77r2XESNWYaWVV2bQoEHssutuXHftn4sOqyU1Yjaf7nINsg+Z1dHBGYfsxKuT\nn+cTO+3F8musU3RIfd6UKZMZPny52c+HDRvOvffeU+UdfZf69ZEapKQVJT3cgO3sK+nM/HgnSaNK\nXrtVUl0zdvQV/fr354hzr+Xbl9/JC48/yEvPPlF0SH1eRMy1roimZDsoogbZm5rYOwHuuKnDkIUX\nZeW1N+aJe28vOpQ+b9iw4Uya9MLs55MnT2LZZZctMKLWVE9y7G0Jsr+kcyU9IukmSUMkjZB0g6Tx\nku6QtDqApM9JuiffZOdmScuUbkjSpsCOwCmSJkoakV/aRdK9kp6QtHkue4ekdUre+w9JazXpMxfm\n7ddf5b233wRgxgfv89SEf7LU8isXHJVtsOGGPPXUkzz37LNMnz6dKy67lB3G7lh0WC2pr/VBrgrs\nHhEHSboc+CJpZt9DIuJJSRsDvwK2Au4ENomIkHQg8C3g6M4NRcQ/JV0DXBcRf4TZzZQBEbGRpO2B\n7wPbAOeRbvl4pKTVgMER8VBzPnJx3np1Kpf/9JvErFnErFl8fMvtWeMTWxUdVp83YMAAfnH6mXxu\nh8/S0dHBV/bdn1GjRxcdVksqog+yyAT5bJ7ZF2A8sCKwKXBFyTfB4Pz/cOAySR8DBgHP1rmPq7ps\nH+AK4LuSvgnsD1xQ7o35bmgHAyy+TPs3eT42YnWOOOfaosOwMsZstz1jttu+6DBaXl+7kuaDkscd\nwDLA6xFR7tTqGcCpEXGNpC2BE7q5jw7yZ42IdyWNAz4PfJkKU69HxDnAOQDDR3587p50M2sej4Pk\nTeBZSbsAKFk7v7YYMDk//kqF978FLFLnvs4DfgncFxGvzWO8ZtYkIg3brbU0WislSIA9gQMkPQg8\nQqrlQaoxXiHpDmBahfdeCnwzn8gZUaEMABExnpSQz29I1GbWw0S/frWXRiukiR0RzwFrljz/ecnL\nY8qU/zMw1+UFEXEBuQ8xIv7BnMN8tiwpN40P+yCRtCzpy+GmeYnfzJqvUU1sSc+RWpwdwMyIqDhe\nus9dSSNpH+Ak4KiImFV0PGZWh8Y3oT+dK05V9bkEGREXAhcWHYeZ1U/QI03oWlqtD9LMrKw6+yCH\nSrq/ZDm4zKYCuClfkFLu9dn6XA3SzNpQ/U3sadX6FLPNImKKpKWBcZIej4iy1926BmlmLS8N82nM\npYYRMSX//wpwNbBRpbJOkGbWBhozWYWkhSQt0vkY2BaoOLOYm9hm1hYadJJmGeDqzrkagIsj4oZK\nhZ0gzaz1NWiYT0Q8A6xds2DmBGlmLa+zD7LZnCDNrC0UMdG6E6SZtYUiBoo7QZpZ6ytoujMnSDNr\neZ3TnTWbE6SZtYGeuedMLU6QZtYW3AdpZlZOD80YXosTpJm1PI+DNDOrwgnSzKwC90GamZXjPkgz\ns/LkYT5mZpW5BmlmVkH/VuqDlLRotTdGxJuND8fMbG5qwWuxHyHd/as0qs7nASzfg3GZmc2hgApk\n5QQZEcs1MxAzs2qKqEHWddMuSbtJ+k5+PFzS+j0blpnZhwT0k2oujVYzQUo6E/g0sHde9S5wdsMj\nMTOrop9qL41Wz1nsTSNiPUkPAETEa5IGNT4UM7MKunHf6/o2p/7A/cDkiBhbqVw9CXKGpH6kEzNI\n+ggwqyFRmpnVqcEt6COAx4Cqo3Xq6YM8C7gSWErSD4A7gZ/Od3hmZnUSaRxkraWubUnDgR2A82qV\nrVmDjIgLJY0HtsmrdomIh+uKxMysQepsYg+VdH/J83Mi4pwuZU4DvgUsUmtj9V5J0x+YQWpm13Xm\n28ysUVT/ZBXTImKDytvRWOCViBgvactaG6vnLPZxwCXAssBw4GJJ364rVDOzBmnQMJ/NgB0lPQdc\nCmwl6feVCtdTg9wLWD8i3gWQdBIwHvhJPdGYmTVCI8Y5RsS3gW8D5BrkMRGxV6Xy9STI57uUGwA8\nMx8xmpl1Sxoo3vz9Vpus4hekPsd3gUck3Zifb0s6k21m1hwNHgcJEBG3ArdWK1OtBtl5pvoR4PqS\n9XfPV1RmZvOgpeaDjIjfNDMQM7NKOsdBNlvNPkhJI4CTgFHAAp3rI2K1HozLzGwOrTqbzwXA+aQk\nvh1wOen0uJlZ06iOpdHqSZALRsSNABHxdEQcT5rdx8ysKaRipjurZ5jPB0p126clHQJMBpZueCRm\nZlW06n2xvwEsDBxO6otcDNi/J4MyM+uqpc5id4qIe/LDt/hw0lwzs6YRPdOErqXaQPGryXNAlhMR\nX+iRiFrQMgsP5ojNRxQdhnWxxIaHFR2CNUv9k1U0VLUa5JlNi8LMrIb+rVSDjIi/NTMQM7NKROvd\nF9vMrGW01GQVZmatpKUTpKTBEfFBTwZjZlaOVMy12PXMKL6RpH8BT+bna0s6o8cjMzMr0XnbhWpL\no9VzqeEvgbHAqwAR8SC+1NDMmihNmNualxr2i4jnu5xB6mh4JGZmVRRxt8B6EuQLkjYCQlJ/4OvA\nEz0blpnZh6T673vdSPUkyENJzezlgZeBm/M6M7OmabUraQCIiFeA3ZoQi5lZRS05zEfSuZS5Jjsi\nDu6RiMzMuug8STPf25EWAG4HBpPy3x8j4vuVytfTxL655PECwM7AC/MTpJlZtwj6N+YszQfAVhHx\ntqSBwJ2S/hoRZW9GWE8T+7I54pQuAsY1JFQzszqpATdViIgA3s5PB+al4qxl85KTVwJWmIf3mZnN\nk9TErr0AQyXdX7LM1RUoqb+kicArwLiSOW/nUk8f5H/5MMP2A14Dju3+RzQzm3d1nqSZFhEbVCsQ\nER3AOpIWB66WtGZEPFyubNUEme9FszbpPjQAs3IV1cysaXrivtgR8bqkW4ExQNkEWbWJnZPh1RHR\nkRcnRzNrvjquw67nJLekpXLNEUlDgG2AxyuVr+cs9r2S1ouICXV+FDOzhmvQtdYfA36XrwrsB1we\nEddVKlztnjQDImIm8EngIElPA++QarsREes1Ilozs1o6T9LMr4h4CFi33vLVapD3AusBO81vUGZm\n80etdU8aUtImIp5uUixmZmWle9I0f7/VEuRSko6q9GJEnNoD8ZiZzU2tdy12f2BhaMDwdTOz+dQT\nE+LWUi1BvhgRJzYtEjOzCnpiHGQ9avZBmpm1glbrg9y6aVGYmVUhWuyWCxHxWjMDMTOrSOm2C81W\n932xzcyKImi5cZBmZi2jiJMiTpBm1hZa7SSNmVmLkPsgzczKcR+kmVkV7oM0MyvHw3zMzMpruYHi\nZmatpNUmqzAzaxke5mNmVkZqYrsGaWZWlmuQZmZlqZA+yCJODJmZdUtnE7vWUnM70nKSbpH0mKRH\nJB1RrbxrkGbW+tSwJvZM4OiImCBpEWC8pHER8Wi5wq5BmllbkGovtUTEixExIT9+C3gMGFapvBNk\nH3HTjTew1uiRjF59FU752clFh2PZqisszd2XHjt7efmOUzhsjy2LDqvldF6LXWsBhkq6v2Q5uOI2\npRWBdYF7KpVxE7sP6Ojo4MjDv8b1fx3HsOHD+eQmGzJ27I6sMWpU0aH1eU8+/wqb7Ja+sPr1E0/f\neBLX3PJgwVG1JtU3zGdaRGxQc1vSwsCVwJER8Walcq5B9gH33XsvI0aswkorr8ygQYPYZdfduO7a\nPxcdlnXx6Y1G8uykqfznxf8WHUpLakQTO21HA0nJ8Q8RcVW1sk6QfcCUKZMZPny52c+HDRvO5MmT\nC4zIytnls+tz+Q3jiw6jZamOfzW3kWa8+A3wWEScWqt80xKkpBMkHSPpREnbNGu/1UjaV9KZRcfR\n0yJirnVFzIxilQ0c0J8dtvg4V417oOhQWpKo3f9Y53yRmwF7A1tJmpiX7SsVbnofZER8r9n77OuG\nDRvOpEkvzH4+efIkll122QIjsq4++8lRTHz8BV557a2iQ2lNDRrmExF30o2pJXu0BinpOEn/lnQz\nMDKvu0DSl/LjkyU9KukhST/P65aSdKWk+/KyWV6/kaR/Snog/9+5vdGS7s3fBA9JWjWv36tk/a8l\n9c/r95P0hKTbSN8mvd4GG27IU089yXPPPsv06dO54rJL2WHsjkWHZSW+PGYDN69rUB1Lo/VYDVLS\n+sBupNPoA4AJwPiS15cEdgZWj4iQtHh+6XTgFxFxp6TlgRuBNYDHgU9FxMzcRP8x8EXgEOD0iPiD\npEFAf0lrALsCm0XEDEm/AvaUNA74AbA+8AZwC1C2TZOHBxwMsNzyyzfs51KEAQMG8IvTz+RzO3yW\njo4OvrLv/owaPbrosCwbssBAttp4dQ770SVFh9KyRO+b7mxz4OqIeBdA0jVdXn8TeB84T9L1wHV5\n/TbAqJI+skXziPfFgN/lGmIAA/PrdwHHSRoOXBURT0rampQE78vbGQK8AmwM3BoRU3NMlwGrlQs+\nIs4BzgFYf/0N5u7EazNjttueMdtV7GqxAr33/gyGf/r/FR1Gy+uNk1VUTCy5JrgRsDWppnkYsBWp\n2f+JiHivtLykM4BbImLnPMDz1rydiyXdA+wA3CjpQNIXzu8i4ttdtrFTtZjMrHXVOQ6yoXqyD/J2\nYGdJQ3IN8HOlL+aBmotFxF+AI4F18ks3kZJlZ7nO9YsBnWNT9i15fWXgmYj4JXANsBbwN+BLkpbO\nZZaUtAJpxPyWkj6Sx0Lt0sDPa2Y9qFHjILujx2qQ+WLwy4CJwPPAHV2KLAL8WdICpBrfN/L6w4Gz\nJD2U47ud1M/4M1IT+yjg7yXb2RXYS9IM4CXgxIh4TdLxwE2S+gEzgK9FxN2STiA1y18k9Yv2b/BH\nN7Me0OvuahgRJwEnVSmyUZn3TCMlva7r72LO/sLv5vU/AX5SpvxlwGVl1p8PnF8rdjNrHcJ3NTQz\nK6+HmtC1OEGaWVvodU1sM7OGcQ3SzKycYu5J4wRpZi2vpy4lrMUJ0szag5vYZmblFXEljROkmbWF\nfq5BmpmVUVAnpBOkmbUFN7HNzMpIlxo2f79OkGbWFpwgzcwq6G3zQZqZNUwj5oOU9FtJr0h6uJ59\nOkGaWVto0E27LgDG1LtPN7HNrOU1aj7IiLg937KlLk6QZtb66p8Pcqik+0uen5NvwDdPnCDNrC3U\nWX+cFhEbNGqfTpBm1h48zMfMrJxi5oP0WWwza3n1nMGuJ31KuoR0V9ORkiZJOqBaedcgzaw9NKAC\nGRG7d6e8E6SZtQVPVmFmVoHngzQzK8f3xTYzq8ZNbDOzuXg+SDOzKtwHaWZWgc9im5lV4hqkmVl5\nBeRHJ0gza30ShVyL7QRpZu3BTWwzs/LcxDYzq8DjIM3MypDngzQzay2uQZpZW3AT28ysAl9JY2ZW\nRhoH2fz9OkGaWXtwgjQzK6+IJrbPYptZW5BqL/VtR2Mk/VvSU5KOrVbWCdLM2kIjEqSk/sBZwHbA\nKGB3SaMqlXeCNLO2oDr+1WEj4KmIeCYipgOXAp+vVNh9kHWYMGH8tCED9XzRcTTIUGBa0UHYXHrb\ncVmhkRt7YML4GxccpKF1FF1A0v0lz8+JiHNKng8DXih5PgnYuNLGnCDrEBFLFR1Do0i6PyI2KDoO\nm5OPS3URMaZBmypXzYxKhd3ENrO+ZBKwXMnz4cCUSoWdIM2sL7kPWFXSSpIGAbsB11Qq7CZ233NO\n7SJWAB+XJoiImZIOA24E+gO/jYhHKpVXRMXmt5lZn+YmtplZBU6QZmYVOEGamVXgBGnWRiSNkuTx\nkk3iBGll5SEQ1kIkLUy6LO4wSesVHU9f4ARpc5G0LvC9ouOwD0lSRLwN/B54BvhqtUkWrDGcIK2c\nqcDOkhp1eZfNp/hwPN5ngdHApsA33NzuWR4HabNJGgjMiogOSfsDC0XEGZL6RcSsouPr6yRtDvwf\n8Im8rAusBJxRbbCzzTvXIA0ASaOBK4Cv5abbBGA/Scs4ORZDSjMcdv4PLAY8HxFvRcRNwM3ASOC7\nktYuKMxezQnSAMg1kM7L3a4iXdA/GNhbWWHB9UG5z7Gzebdk/v92YKakAwEiYjzwIKlP8uXmR9n7\nuYndB0laApgZEW9J2gEYS5rR5JcR8UZuyq0EfBV4MyK2KzDcPk3SocDWwCOkRPguMAaYQZp44WDg\nCxExubAgezHXIPuYPHznN8AhkjYCfkSqhSwL3CRpyYi4IyIuBLYkTUB6UGEB92GSdgf2AI4hnZxZ\nBbgB+BkwnXSy5kAnx57jGmQf0tlsy2c+fwS8BNwbEb/Kr59GmpJ+bES8ltcdR6pt/rSouPuK0mZ1\n7tL4GjCRVJvfB9ghIqZLWjoiXvHJs57nGmQfIWkIsHx++jjwfVKtcUNJiwNExJHAv4CbJQ2QNBT4\nGPCXAkLuU7okx4/mx1NI4x73j4jP5OR4OHCApP5Ojj3PNcg+QtLHgR2AgcB+pDu6rQKcBlwLXBAR\nb+SyoyLi0fx4cER8UEzUfY+ko4BPAfsCSwDHAS8C55OG9hwD7OVhPc3hGmQvJ2lpSftGxL9INcbj\ngTMj4v2IeBj4FrA9qU+ysyb5qKR++bGTY5Pks9NfBA6JiNdJZ6b/CLwOnAvsAuzj5Ng8rkH2cpLG\nkjr6bwEeJl3LO4jU2X9XPpO9MfBTYN+IeK6oWPu6XHt8iXQl0zrAzqTa/VmkG0vNiIj3i4uw7/Et\nF3q/v5OO8zZAv4g4VtLRpNrIm3nIz6LAzhHx3wLj7FO6jHPs9ALpuCwN/DovWwALRMQrTQ7RcILs\ntTr/ACPiXUnjSDWQHSXNjIj/lXQMqS9ye+BwJ8fm6XJC5hBSX2MHcApwPTAgIt6UtB2wJuneKVYA\nN7F7oZLhPJuQ/rjeioiHJO1IamLfEREXSPoIsHhEPF2hRmM9SNKRwE6kEzG/Ap4E9shnqw8CDgd2\nz33FVgCfpOmFcnIcS2qibQ78XNKuEXEN6TLCz0g6PCJejYinO99TYMh9jqRlSSMJdiAdo6dJg7+v\nkjSANHh/RyfHYrmJ3QtJWoV0dnoH0mVpQ0nzBw7JNccBpMvWrEm61tAjYoqk7wAbkhLhppLWAW4C\nLoqI3YuK1T7kBNk7vQscAqy8Ki6HAAAGZklEQVQIHEZqxu0IfE/SwIg4t8DY+pwufY67k7o93ouI\nKyVNB+7NRdcAfg5cVkyk1pWb2L1AybRYq0saDkzPA71HAOfloTuvANeQrpSxJipJjoeSvrCmAVdI\n2pY0xvHjki4gDbW6OiKeLypWm5NrkL1A7nPcjvQHdjlpHsfNgFnAwTl/Hg7sHRH3FBdp35QH3S8N\nfJo0c9KXSXM53hIRMyTtAXwUOMHjUFuLE2QvkPscv08aWLwx8A6pCXdRTo7DgCOdHJunTJ/jS5Ke\nA04kXRP/+ZwcjyIlygcKCtWqcIJsU3mygo789L/AH4D1gSNJ8wO+IekzwJUR8W5+j4fyNEGXPse9\ngIVIIwoWAfYkDa2aJenL+fmVhQVrVXkcZJuRtEhEvJUff5o05f4zwNmkL7wRuWayCfAT0nyBTxcW\ncB+Wa4e7kS7h7Jz842JgKdIEFCNJx8f9wi3KNcg2ImlB4HpJvySNkzsT+DfwGPAn0pyBh0maCexP\n6tNycmwSSasCgyLikTzOcTvSGMcFcm1xHdIxGkWqTb4QEf8pLGCryTXINiNpZ+BY4DXg2Ih4UNLe\nwAqkuRsHkyaleCQixrlZ3RySViJNUfZj0rXTb0i6gjTU6mFSv/AqpMko9vMxaQ+uQbaZiLha0tuk\ns9XbkmqSl5DOjC4MPBERp5eU9x9iD8tDqw4CJpFuxbpLHrazD+meMX+OiOfySIMdSMPrOipszlqI\nE2QbyjXD/YCTJE2KiEskdQ4ufrDI2PqoycATwGqkpvNHgC8BV3R+WeXrrvch9Uc6ObYJJ8g2FRF/\nyldh/FDSoIj4HXBx0XH1NSUTg8wi9TH2B24k3VDri5IWIk1CsSLwFZ+QaS/ug2xzeYaek0nzPb7k\n+5Q0n6Q9ScOrDiA1tV8j9TmuBLwFXAQ86ppj+/Glhm0uz9CzRURMcXIszEjg8oh4CDiaNC51M1Kf\n5BDgRSfH9uQE2QtExNSiY+jjJgCbSRodEdMj4jTSpYUzSEOtphUbns0r90Gazb9bSdOW7S7p76Ra\n4zTStGWvFhmYzR/3QZo1QB4Y/oW8zASO9gmZ9ucEadZA+ay1IuLtomOx+ecEaWZWgU/SmJlV4ARp\nZlaBE6SZWQVOkGZmFThBmplV4ARpdZPUIWmipIclXZEn8J3XbW0p6br8eEdJx1Ypu7ik/5mHfZwg\n6Zh613cpc4GkL3VjXytKeri7MVprc4K07ngvItaJiDWB6aR7b8+mpNu/UxFxTUScXKXI4kC3E6TZ\n/HKCtHl1B7BKrjk9JulXpGuSl5O0raS7JE3INc2FASSNkfS4pDtJV5yQ1+8r6cz8eBlJV0t6MC+b\nkmYrGpFrr6fkct+UdJ+khyT9oGRbx0n6t6SbSZNIVCXpoLydByVd2aVWvI2kOyQ9IWlsLt9f0ikl\n+/7q/P4grXU5QVq3SRpAut9K56V0I4ELI2Jd0jRfxwPbRMR6wP3AUZIWAM4FPke6T8tHK2z+l8Bt\nEbE2sB7wCOkWE0/n2us3JW0LrApsRJqDcX1Jn5K0PukmWeuSEvCGdXycqyJiw7y/x0hTlnVaEdiC\nNAv42fkzHAC8EREb5u0flG+3YL2QJ6uw7hgiaWJ+fAfwG2BZ4PmIuDuv34R0U6p/5HtyDwLuAlYH\nno2IJwEk/Z50O4KutiLNvE2eIuwNSUt0KbNtXjrvJb0wKWEuAlxdcpvba+r4TGtK+hGpGb8wabLb\nTpfnKeSelPRM/gzbAmuV9E8ulvf9RB37sjbjBGnd8V5ErFO6IifBd0pXAeMiYvcu5dYBGnVdq4Cf\nRMSvu+zjyHnYxwXATvnmZ/sCW5a81nVbkff99YgoTaRIWrGb+7U24Ca2NdrdpLkRV4F0q1pJqwGP\nAytJGpHL7V7h/X8DDs3v7S9pUdKs3IuUlLkR2L+kb3OYpKWB24GdJQ2RtAipOV/LIsCLkgYCe3Z5\nbRdJ/XLMK5NusXsjcGguj6TV8gQV1gu5BmkNFRFTc03sEkmD8+rjI+IJSQeT7us9DbgTWLPMJo4A\nzpF0AOnOf4dGxF2S/pGH0fw190OuAdyVa7BvA3tFxIR887KJwPOkboBavgvck8v/izkT8b+B24Bl\ngEMi4n1J55H6Jico7XwqsFN9Px1rN57Nx8ysAjexzcwqcII0M6vACdLMrAInSDOzCpwgzcwqcII0\nM6vACdLMrIL/D3GrNwez4rnBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff215d8a668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=[\"healthy\", \"diseased\"],\n",
    "                      title='Confusion matrix, without normalization')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
